{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T12:07:23.418986Z",
     "iopub.status.busy": "2020-10-18T12:07:23.417413Z",
     "iopub.status.idle": "2020-10-18T12:07:23.419769Z",
     "shell.execute_reply": "2020-10-18T12:07:23.418144Z"
    },
    "id": "EGq9FCG2GB5_",
    "papermill": {
     "duration": 0.034401,
     "end_time": "2020-10-18T12:07:23.419898",
     "exception": false,
     "start_time": "2020-10-18T12:07:23.385497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rlDqxxCGE4A",
    "papermill": {
     "duration": 0.022072,
     "end_time": "2020-10-18T12:07:23.464345",
     "exception": false,
     "start_time": "2020-10-18T12:07:23.442273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T12:07:23.520864Z",
     "iopub.status.busy": "2020-10-18T12:07:23.514951Z",
     "iopub.status.idle": "2020-10-18T12:07:29.819567Z",
     "shell.execute_reply": "2020-10-18T12:07:29.818927Z"
    },
    "id": "olbEtUui240t",
    "papermill": {
     "duration": 6.333257,
     "end_time": "2020-10-18T12:07:29.819689",
     "exception": false,
     "start_time": "2020-10-18T12:07:23.486432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../input/lish-moa/sample_submission.csv')\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets_scored= pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Qd94QnlGQDB",
    "papermill": {
     "duration": 0.015532,
     "end_time": "2020-10-18T12:07:29.852696",
     "exception": false,
     "start_time": "2020-10-18T12:07:29.837164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocesado de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015961,
     "end_time": "2020-10-18T12:07:29.884393",
     "exception": false,
     "start_time": "2020-10-18T12:07:29.868432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### EliminaciÃ³n de Features non scored con pocos casos positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T12:07:29.925876Z",
     "iopub.status.busy": "2020-10-18T12:07:29.925229Z",
     "iopub.status.idle": "2020-10-18T12:07:29.953187Z",
     "shell.execute_reply": "2020-10-18T12:07:29.952675Z"
    },
    "papermill": {
     "duration": 0.053204,
     "end_time": "2020-10-18T12:07:29.953298",
     "exception": false,
     "start_time": "2020-10-18T12:07:29.900094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_nonscored = train_targets_nonscored.drop('sig_id', axis = 1, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T12:07:29.994002Z",
     "iopub.status.busy": "2020-10-18T12:07:29.993075Z",
     "iopub.status.idle": "2020-10-18T12:07:30.045682Z",
     "shell.execute_reply": "2020-10-18T12:07:30.045137Z"
    },
    "papermill": {
     "duration": 0.076314,
     "end_time": "2020-10-18T12:07:30.045782",
     "exception": false,
     "start_time": "2020-10-18T12:07:29.969468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ones = []\n",
    "bound = 25 #@param {type:\"slider\", min:1, max:50, step:1}\n",
    "for col in y_nonscored.columns:\n",
    "  if(y_nonscored[col].sum() > bound):\n",
    "    ones.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T12:07:30.087365Z",
     "iopub.status.busy": "2020-10-18T12:07:30.086476Z",
     "iopub.status.idle": "2020-10-18T12:07:30.090899Z",
     "shell.execute_reply": "2020-10-18T12:07:30.090405Z"
    },
    "papermill": {
     "duration": 0.02887,
     "end_time": "2020-10-18T12:07:30.090988",
     "exception": false,
     "start_time": "2020-10-18T12:07:30.062118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_nonscored = y_nonscored[ones]\n",
    "len(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T12:07:30.134298Z",
     "iopub.status.busy": "2020-10-18T12:07:30.132183Z",
     "iopub.status.idle": "2020-10-18T12:07:30.380968Z",
     "shell.execute_reply": "2020-10-18T12:07:30.380397Z"
    },
    "id": "S6UZK0UYH5B0",
    "papermill": {
     "duration": 0.273165,
     "end_time": "2020-10-18T12:07:30.381075",
     "exception": false,
     "start_time": "2020-10-18T12:07:30.107910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model Features\n",
    "X =  train_features.drop('sig_id', axis = 1, inplace = False)\n",
    "X = pd.get_dummies(X, columns = ['cp_type', 'cp_time', 'cp_dose'])\n",
    "\n",
    "#Scored target\n",
    "y_scored = train_targets_scored.drop('sig_id', axis = 1, inplace = False)\n",
    "#Non scored target\n",
    "#y_nonscored = train_targets_nonscored.drop('sig_id', axis = 1, inplace = False)\n",
    "#Merged target\n",
    "y = pd.concat([y_scored,y_nonscored],  axis = 1, sort = False)\n",
    "\n",
    "#Targets test\n",
    "y_test = sample_submission.copy()\n",
    "for col in y_test.loc[:, y_test.columns != 'sig_id'].columns:\n",
    "    y_test[col].values[:] = 0\n",
    "    \n",
    "#Test features\n",
    "sig_id_test = test_features['sig_id']\n",
    "X_test = test_features.drop('sig_id', axis = 1, inplace = False)\n",
    "X_test = pd.get_dummies(X_test, columns = ['cp_type', 'cp_time', 'cp_dose'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uec2fMO7KO-H",
    "papermill": {
     "duration": 0.01643,
     "end_time": "2020-10-18T12:07:30.414575",
     "exception": false,
     "start_time": "2020-10-18T12:07:30.398145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxGC2Kq1ZnNv",
    "papermill": {
     "duration": 0.01658,
     "end_time": "2020-10-18T12:07:30.447888",
     "exception": false,
     "start_time": "2020-10-18T12:07:30.431308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T12:07:30.486527Z",
     "iopub.status.busy": "2020-10-18T12:07:30.485816Z",
     "iopub.status.idle": "2020-10-18T12:07:36.174719Z",
     "shell.execute_reply": "2020-10-18T12:07:36.175205Z"
    },
    "id": "cT9zBU9QKUEw",
    "papermill": {
     "duration": 5.710554,
     "end_time": "2020-10-18T12:07:36.175351",
     "exception": false,
     "start_time": "2020-10-18T12:07:30.464797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import random\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T12:07:36.221000Z",
     "iopub.status.busy": "2020-10-18T12:07:36.218108Z",
     "iopub.status.idle": "2020-10-18T12:07:36.223763Z",
     "shell.execute_reply": "2020-10-18T12:07:36.223113Z"
    },
    "id": "O1uDeF9-I8tT",
    "papermill": {
     "duration": 0.031047,
     "end_time": "2020-10-18T12:07:36.223856",
     "exception": false,
     "start_time": "2020-10-18T12:07:36.192809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "  model = tf.keras.Sequential([\n",
    "      #Input layer\n",
    "      tf.keras.layers.Input(879),\n",
    "      #Dense layer 1\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.2),\n",
    "      tfa.layers.WeightNormalization(tf.keras.layers.Dense(2096*1.2, activation = \"relu\")),\n",
    "      #Dense layer 2\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.5),\n",
    "      tfa.layers.WeightNormalization(tf.keras.layers.Dense(1024*1.2, activation = \"relu\")),\n",
    "      #Output layer\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dropout(0.4),\n",
    "      tfa.layers.WeightNormalization(tf.keras.layers.Dense(248, activation = \"sigmoid\")),\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer = tfa.optimizers.Lookahead(tf.keras.optimizers.Adam()),\n",
    "                loss = 'binary_crossentropy',\n",
    "                metrics = ['accuracy', 'AUC'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVE1jtJuZk1j",
    "papermill": {
     "duration": 0.017616,
     "end_time": "2020-10-18T12:07:36.258735",
     "exception": false,
     "start_time": "2020-10-18T12:07:36.241119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T12:07:36.297653Z",
     "iopub.status.busy": "2020-10-18T12:07:36.297002Z",
     "iopub.status.idle": "2020-10-18T12:07:37.014384Z",
     "shell.execute_reply": "2020-10-18T12:07:37.013248Z"
    },
    "id": "gI4heCjzZkg-",
    "papermill": {
     "duration": 0.738261,
     "end_time": "2020-10-18T12:07:37.014515",
     "exception": false,
     "start_time": "2020-10-18T12:07:36.276254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T12:07:37.065662Z",
     "iopub.status.busy": "2020-10-18T12:07:37.064467Z",
     "iopub.status.idle": "2020-10-18T17:23:36.925296Z",
     "shell.execute_reply": "2020-10-18T17:23:36.925978Z"
    },
    "id": "IM0Z3ro5LbiL",
    "outputId": "2f2d1155-7b92-4c5f-f9ea-4f047cd5ac2b",
    "papermill": {
     "duration": 18959.893576,
     "end_time": "2020-10-18T17:23:36.926203",
     "exception": false,
     "start_time": "2020-10-18T12:07:37.032627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080c3eda58024a88a1d9fb1a14622ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "TRAIN : \n",
      " [0.0076660457998514175, 0.3995072841644287, 0.9911465644836426]\n",
      "VAL  : \n",
      " [0.01477705966681242, 0.13431833684444427, 0.7994850873947144]\n",
      "Validation predicted\n",
      "Test predicted\n",
      "FOLD 2\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "TRAIN : \n",
      " [0.006742239464074373, 0.44980964064598083, 0.9953730702400208]\n",
      "VAL  : \n",
      " [0.014310508035123348, 0.14909334480762482, 0.8148269057273865]\n",
      "Validation predicted\n",
      "Test predicted\n",
      "FOLD 3\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "TRAIN : \n",
      " [0.0071014780551195145, 0.4303247332572937, 0.993890106678009]\n",
      "VAL  : \n",
      " [0.013949237763881683, 0.13297514617443085, 0.8219115734100342]\n",
      "Validation predicted\n",
      "Test predicted\n",
      "FOLD 4\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "TRAIN : \n",
      " [0.007152525242418051, 0.4274580180644989, 0.9940409660339355]\n",
      "VAL  : \n",
      " [0.01417927723377943, 0.14909334480762482, 0.8020341396331787]\n",
      "Validation predicted\n",
      "Test predicted\n",
      "FOLD 5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "TRAIN : \n",
      " [0.006886409595608711, 0.4393281042575836, 0.9944924712181091]\n",
      "VAL  : \n",
      " [0.014022916555404663, 0.14573539793491364, 0.8099023699760437]\n",
      "Validation predicted\n",
      "Test predicted\n",
      "FOLD 6\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "TRAIN : \n",
      " [0.008144766092300415, 0.3722732365131378, 0.9880284070968628]\n",
      "VAL  : \n",
      " [0.014543560333549976, 0.14775016903877258, 0.8101707696914673]\n",
      "Validation predicted\n",
      "Test predicted\n",
      "FOLD 7\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "TRAIN : \n",
      " [0.008284016512334347, 0.36809101700782776, 0.987626850605011]\n",
      "VAL  : \n",
      " [0.01397079136222601, 0.15322580933570862, 0.8273977041244507]\n",
      "Validation predicted\n",
      "Test predicted\n",
      "FOLD 8\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "TRAIN : \n",
      " [0.008942794986069202, 0.32907819747924805, 0.9816663265228271]\n",
      "VAL  : \n",
      " [0.014287197031080723, 0.14448924362659454, 0.823397159576416]\n",
      "Validation predicted\n",
      "Test predicted\n",
      "FOLD 9\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "TRAIN : \n",
      " [0.007116179447621107, 0.42900654673576355, 0.9940609335899353]\n",
      "VAL  : \n",
      " [0.01403399184346199, 0.1666666716337204, 0.8181020617485046]\n",
      "Validation predicted\n",
      "Test predicted\n",
      "FOLD 10\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "TRAIN : \n",
      " [0.007031671702861786, 0.434650182723999, 0.9942975044250488]\n",
      "VAL  : \n",
      " [0.014441262930631638, 0.14247311651706696, 0.8131512999534607]\n",
      "Validation predicted\n",
      "Test predicted\n",
      "FOLD 11\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "TRAIN : \n",
      " [0.00710931234061718, 0.42712533473968506, 0.9933819770812988]\n",
      "VAL  : \n",
      " [0.015056001022458076, 0.14717741310596466, 0.791159987449646]\n",
      "Validation predicted\n",
      "Test predicted\n",
      "FOLD 12\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "TRAIN : \n",
      " [0.008153722621500492, 0.36791184544563293, 0.9883415102958679]\n",
      "VAL  : \n",
      " [0.014425335451960564, 0.15793010592460632, 0.8136903047561646]\n",
      "Validation predicted\n",
      "Test predicted\n",
      "FOLD 13\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "TRAIN : \n",
      " [0.007240341976284981, 0.4222879111766815, 0.9931094646453857]\n",
      "VAL  : \n",
      " [0.013753063976764679, 0.14448924362659454, 0.8238548040390015]\n",
      "Validation predicted\n",
      "Test predicted\n",
      "FOLD 14\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "TRAIN : \n",
      " [0.00845713447779417, 0.3509361147880554, 0.9862477779388428]\n",
      "VAL  : \n",
      " [0.014556380920112133, 0.14986559748649597, 0.8309260010719299]\n",
      "Validation predicted\n",
      "Test predicted\n",
      "FOLD 15\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "TRAIN : \n",
      " [0.007137330248951912, 0.420809805393219, 0.99384605884552]\n",
      "VAL  : \n",
      " [0.014399188570678234, 0.13104838132858276, 0.8141257762908936]\n",
      "Validation predicted\n",
      "Test predicted\n",
      "FOLD 16\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "TRAIN : \n",
      " [0.007266589906066656, 0.4216160476207733, 0.9930862188339233]\n",
      "VAL  : \n",
      " [0.014220146462321281, 0.15188172459602356, 0.8123390674591064]\n",
      "Validation predicted\n",
      "Test predicted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NFOLD = 16\n",
    "kf = KFold(n_splits = NFOLD)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 216\n",
    "\n",
    "#Valores en forma de array para poder enchufarlos a la red\n",
    "X_vals = X.values\n",
    "y_vals = y.values\n",
    "val_pred = np.zeros((train_features.shape[0], 248)) #Grid vacia para la predicciÃ³n del validation split\n",
    "test_pred = np.zeros((test_features.shape[0], 248)) #Grid vacÃ­a par ala predicciÃ³n del test\n",
    "\n",
    "#Kfold para train set y validation set\n",
    "cnt = 1\n",
    "for tr_idx, val_idx in tqdm(kf.split(X_vals)):\n",
    "\n",
    "  #Reduccion del learning rate a medida que nuestro modelo se estanca\n",
    "  reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                     factor=0.1, \n",
    "                                     patience=3, \n",
    "                                     verbose=1,\n",
    "                                     min_delta=1e-4, \n",
    "                                     mode='min')\n",
    "\n",
    "  print(f'FOLD {cnt}')\n",
    "  cnt+=1\n",
    "\n",
    "  net = model()\n",
    "  net.fit(X_vals[tr_idx], y_vals[tr_idx], \n",
    "          batch_size = BATCH_SIZE,\n",
    "          epochs = EPOCHS,\n",
    "          validation_data = (X_vals[val_idx], y_vals[val_idx]),\n",
    "          verbose = 0,\n",
    "          callbacks = [reduce_lr_loss])\n",
    "    \n",
    "  #ImpresiÃ³n de los resultados\n",
    "  print(\"TRAIN : \\n\", net.evaluate(X_vals[tr_idx],y_vals[tr_idx],\n",
    "                                  verbose = 0,\n",
    "                                  batch_size = BATCH_SIZE))\n",
    "\n",
    "  print(\"VAL  : \\n\", net.evaluate(X_vals[val_idx], y_vals[val_idx],\n",
    "                                  verbose = 0,\n",
    "                                  batch_size = BATCH_SIZE))\n",
    "\n",
    "  #PredicciÃ³n de los valores de validaciÃ³n\n",
    "  val_pred[val_idx] = net.predict(X_vals[val_idx],\n",
    "                                  batch_size = BATCH_SIZE,\n",
    "                                  verbose = 0)\n",
    "\n",
    "  print(\"Validation predicted\")\n",
    "\n",
    "  #PredicciÃ³n final del test\n",
    "  test_pred += net.predict(X_test,\n",
    "                          batch_size = BATCH_SIZE,\n",
    "                          verbose = 0)/ NFOLD\n",
    "\n",
    "  print(\"Test predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T17:23:37.463226Z",
     "iopub.status.busy": "2020-10-18T17:23:37.462509Z",
     "iopub.status.idle": "2020-10-18T17:23:37.466228Z",
     "shell.execute_reply": "2020-10-18T17:23:37.465725Z"
    },
    "id": "M-H8DVgIlNk5",
    "papermill": {
     "duration": 0.273268,
     "end_time": "2020-10-18T17:23:37.466341",
     "exception": false,
     "start_time": "2020-10-18T17:23:37.193073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns = y_scored.columns # Cogemos el nombre de las columnas\n",
    "\n",
    "final_sub  = pd.DataFrame(data = test_pred[:,:206], columns = columns)\n",
    "final_sub.insert(0, column = 'sig_id', value = y_test['sig_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.265197,
     "end_time": "2020-10-18T17:23:37.995349",
     "exception": false,
     "start_time": "2020-10-18T17:23:37.730152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T17:23:38.529717Z",
     "iopub.status.busy": "2020-10-18T17:23:38.529024Z",
     "iopub.status.idle": "2020-10-18T17:23:40.643788Z",
     "shell.execute_reply": "2020-10-18T17:23:40.642590Z"
    },
    "id": "ob6m72aLnOpc",
    "papermill": {
     "duration": 2.382871,
     "end_time": "2020-10-18T17:23:40.643918",
     "exception": false,
     "start_time": "2020-10-18T17:23:38.261047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_sub.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T17:23:41.180173Z",
     "iopub.status.busy": "2020-10-18T17:23:41.178806Z",
     "iopub.status.idle": "2020-10-18T17:23:41.182494Z",
     "shell.execute_reply": "2020-10-18T17:23:41.183181Z"
    },
    "papermill": {
     "duration": 0.27559,
     "end_time": "2020-10-18T17:23:41.183318",
     "exception": false,
     "start_time": "2020-10-18T17:23:40.907728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23814, 248)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T17:23:41.713873Z",
     "iopub.status.busy": "2020-10-18T17:23:41.713073Z",
     "iopub.status.idle": "2020-10-18T17:23:41.717581Z",
     "shell.execute_reply": "2020-10-18T17:23:41.718026Z"
    },
    "papermill": {
     "duration": 0.271925,
     "end_time": "2020-10-18T17:23:41.718162",
     "exception": false,
     "start_time": "2020-10-18T17:23:41.446237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23814, 248)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T17:23:42.381577Z",
     "iopub.status.busy": "2020-10-18T17:23:42.380695Z",
     "iopub.status.idle": "2020-10-18T17:23:42.385231Z",
     "shell.execute_reply": "2020-10-18T17:23:42.386259Z"
    },
    "papermill": {
     "duration": 0.40344,
     "end_time": "2020-10-18T17:23:42.386469",
     "exception": false,
     "start_time": "2020-10-18T17:23:41.983029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_loss_metric(y_true, y_pred):\n",
    "    y_pred_clip = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    loss = - np.mean(np.mean(y_true * np.log(y_pred_clip) + (1 - y_true) * np.log(1 - y_pred_clip), axis = 1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T17:23:43.001714Z",
     "iopub.status.busy": "2020-10-18T17:23:43.000766Z",
     "iopub.status.idle": "2020-10-18T17:23:43.353621Z",
     "shell.execute_reply": "2020-10-18T17:23:43.354426Z"
    },
    "papermill": {
     "duration": 0.621723,
     "end_time": "2020-10-18T17:23:43.354587",
     "exception": false,
     "start_time": "2020-10-18T17:23:42.732864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014936984069045109"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss_metric(y_scored,val_pred[:,:206])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-18T17:23:43.889563Z",
     "iopub.status.busy": "2020-10-18T17:23:43.888640Z",
     "iopub.status.idle": "2020-10-18T17:23:43.890683Z",
     "shell.execute_reply": "2020-10-18T17:23:43.891160Z"
    },
    "papermill": {
     "duration": 0.272386,
     "end_time": "2020-10-18T17:23:43.891275",
     "exception": false,
     "start_time": "2020-10-18T17:23:43.618889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "v4 = 0.016096644893067273\n",
    "v5 = 0.0158627008875029\n",
    "v6 = 0.01577834332535018\n",
    "v7 = 0.015266542185011646\n",
    "v8 = 0.015230647531349884"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.265319,
     "end_time": "2020-10-18T17:23:44.421800",
     "exception": false,
     "start_time": "2020-10-18T17:23:44.156481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Versiones guardadas\n",
    "- Fallidas:\n",
    "    - VersiÃ³n 2 con 4096 neuronas empeora el resultado a 0.01632391606043724\n",
    "\n",
    "\n",
    "- Version 4: submission 4 : 0.016096644893067273 (NN simple con una deep layer)\n",
    "    - Fallos: Faltaba la Ãºltima capa de BatchNormaliztion\n",
    "- Version 5: 0.0158627008875029\n",
    "    - Mejora del fallo de la versiÃ³n 4\n",
    "- VersiÃ³n 6 : 0.01577834332535018\n",
    "     - Cambio de la capa de DropOut a 0.4\n",
    "- VersiÃ³n 7: 0.015266542185011646\n",
    "    - Nueva capa densa\n",
    "    - Uso de un nuevo optimizador\n",
    "    - Uso de normalizaciÃ³n de pesos en cada capa\n",
    "    - AÃ±adidas mÃ¡s capas de dropout\n",
    "- Version 8: 0.015212403062810905\n",
    "    - Reajuste manual de los pesos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.262634,
     "end_time": "2020-10-18T17:23:44.948177",
     "exception": false,
     "start_time": "2020-10-18T17:23:44.685543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 18987.790201,
   "end_time": "2020-10-18T17:23:46.850764",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-18T12:07:19.060563",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "080c3eda58024a88a1d9fb1a14622ffd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5417090b727641a79850994500233a4c",
        "IPY_MODEL_3ca56c623ec4468a9887af85b811788c"
       ],
       "layout": "IPY_MODEL_ca4304d179e94dc1a1c18fea09877fa0"
      }
     },
     "3ca56c623ec4468a9887af85b811788c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_59950ab7078c46e4897d54793bcfddc9",
       "placeholder": "â",
       "style": "IPY_MODEL_97ab86f0496b4e388eb2d1fd1769a847",
       "value": " 16/? [5:15:59&lt;00:00, 1184.98s/it]"
      }
     },
     "4300b7d2ffbc4ccc955c18701a92fe48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "5417090b727641a79850994500233a4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a98a078d62ce452082077aab8fc86314",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4300b7d2ffbc4ccc955c18701a92fe48",
       "value": 1.0
      }
     },
     "59950ab7078c46e4897d54793bcfddc9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "97ab86f0496b4e388eb2d1fd1769a847": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a98a078d62ce452082077aab8fc86314": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ca4304d179e94dc1a1c18fea09877fa0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
