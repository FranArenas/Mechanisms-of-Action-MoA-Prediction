{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Notebook de referencia** https://www.kaggle.com/gogo827jz/rapids-svm-on-gpu-6000-models-in-1-hour"},{"metadata":{"id":"TRBnzsqfS7wu","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm\nfrom time import time","execution_count":null,"outputs":[]},{"metadata":{"id":"lCvaxid2jW7i"},"cell_type":"markdown","source":"# Carga de datos"},{"metadata":{"id":"ZuzUhyN6jHTj","trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/lish-moa/sample_submission.csv')\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\ntrain_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets= pd.read_csv('../input/lish-moa/train_targets_scored.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"5MbLl4I3llRU"},"cell_type":"markdown","source":"# Preprocesado de los datos"},{"metadata":{"id":"PUWKOWEipS38"},"cell_type":"markdown","source":"### Categorical Pipelines"},{"metadata":{"id":"dIitFb4ulbS-","trusted":true},"cell_type":"code","source":"def categorical_encoding(df):\n  df['cp_type'] = df['cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n  df['cp_dose'] = df['cp_dose'].map({'D1': 0, 'D2': 1})\n  df['cp_time'] = df['cp_time'].map({24:1, 48:2, 72:3})\n\n  return df","execution_count":null,"outputs":[]},{"metadata":{"id":"-IRggtc8qSRB"},"cell_type":"markdown","source":"## Preprocess train data"},{"metadata":{"id":"J1Zlj9M3vW6p"},"cell_type":"markdown","source":"## Train"},{"metadata":{"id":"dpbcZdHTqmw1"},"cell_type":"markdown","source":"Delete ID Columns and then we encode categorical labels"},{"metadata":{"id":"C5nIl1qbqkkH","trusted":true},"cell_type":"code","source":"df_train = train_features.copy()\ndf_train.drop('sig_id', axis = 1, inplace = True)\n\ndf_train = categorical_encoding(df_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"40saK2s7vY0F"},"cell_type":"markdown","source":"## Target"},{"metadata":{"id":"nmKrZohYvaUR","trusted":true},"cell_type":"code","source":"train_targets.drop('sig_id', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"id":"sxyEQpHF3BEd"},"cell_type":"markdown","source":"## Test"},{"metadata":{"id":"smXuRLPk3D2O","trusted":true},"cell_type":"code","source":"df_test = test_features.copy()\ndf_test.drop('sig_id', axis = 1, inplace = True)\n\ndf_test = categorical_encoding(df_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"SfASA9pCwbUt"},"cell_type":"markdown","source":"# SVC"},{"metadata":{"id":"qIsrghN6xEPT","trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import StandardScaler\n\nimport datetime","execution_count":null,"outputs":[]},{"metadata":{"id":"2LJRR8C9rYvC","trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\n\nX = scaler.fit_transform(df_train.values)\nX_tt = scaler.transform(df_test.values)","execution_count":null,"outputs":[]},{"metadata":{"id":"SZR5p4tpv-mD","outputId":"250499f0-ffdc-4673-e1ef-0043205a0c5e","trusted":true},"cell_type":"code","source":"#Copies\nres = train_targets.copy()\ntrain = df_train.copy()\n\nsample_submission.loc[:, train_targets.columns] = 0 # putting all columns to 0\nres.loc[:, train_targets.columns] = 0 # putting all columns to 0\n\nN_STARTS = 1 #Semillas\nN_SPLITS = 3\n\nfor n in tqdm(range(train_targets.shape[1])):\n\n  start_time = time() #Time for tqdm\n  target = train_targets.values[:,n] #y n column\n\n  if target.sum() >= N_SPLITS:\n\n    for seed in range(N_STARTS):\n\n      skf = StratifiedKFold(n_splits = N_SPLITS, random_state = seed, shuffle = True)\n\n      for j, (train_idx, test_idx) in enumerate(skf.split(target, target)):\n\n        x_train, x_test = X[train_idx],X[test_idx]\n        y_train, y_test = target[train_idx], target[test_idx]\n\n        if y_train.sum() >= 5:\n\n          model = SVC(probability = True, cache_size = 2000)\n          model.fit(x_train,  y_train)\n\n          sample_submission.loc[:, train_targets.columns[n]] += model.predict_proba(df_test)[:, 1] / (N_SPLITS * N_STARTS) # Añadimos la media de nuestro valor predicho al conjunto para evaluar\n          res.loc[test_idx, train_targets.columns[n]] += model.predict_proba(x_test)[:, 1] / N_STARTS # Añadimos la media de nuestro valor predicho a nuestro conjunto para medir la métrica\n\n        else: \n\n          print(f'Target {target}: Seed {seed}: Fold {n}: Not enough positive values for give probability.')\n\n          model = SVC(cache_size = 2000)\n\n          model.fit(x_train,  y_train)\n\n          sample_submission.loc[:, train_targets.columns[n]] += model.predict_proba(df_test)[:, 1] / (N_SPLITS * N_STARTS) # Añadimos la media de nuestro valor predicho al conjunto para evaluar\n          res.loc[test_idx, train_targets.columns[n]] += model.predict_proba(x_test)[:, 1] / N_STARTS # Añadimos la media de nuestro valor predicho a nuestro conjunto para medir la métrica\n\n        col_score = log_loss(train_targets.loc[:, train_targets.columns[n]], res.loc[:, train_targets.columns[n]])\n\n        print(f'[{str(datetime.timedelta(seconds = time() - start_time))[2:7]}] Target {target}:', col_score)\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"8nzBrih3ycle","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}